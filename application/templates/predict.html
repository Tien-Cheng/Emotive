<!-- Inherits from layout.html -->
{% extends "layout.html" %}

<!-- The block content replace the one encapsulated in  layout.html -->
{% block content %}

<!-- Greetings -->
<div class="mb-2 mb-md-4 mt-3 mt-md-0">
    <h4 class="text-center header-main">Look at your <span class="text-purple">Camera!</span></h4>
    <h4 class="text-center header-normal mb-0 d-none d-md-block">
        Fit your face inside the center box to get the best results!
    </h4>
</div>

<!-- Camera -->
<div>
    <div class="camera d-flex flex-column align-items-center justify-content-center">

        <!-- Camera Inputs -->
        <div id="videoWrap" class="video-wrap position-relative crop overflow-hidden rounded-3 d-flex flex-column align-items-center justify-content-center">
            <span class="position-absolute top-0 start-0 mt-2 ms-2">
                <svg class="w-6 h-6" fill="rgba(86, 59, 255)" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4 5a2 2 0 00-2 2v8a2 2 0 002 2h12a2 2 0 002-2V7a2 2 0 00-2-2h-1.586a1 1 0 01-.707-.293l-1.121-1.121A2 2 0 0011.172 3H8.828a2 2 0 00-1.414.586L6.293 4.707A1 1 0 015.586 5H4zm6 9a3 3 0 100-6 3 3 0 000 6z" clip-rule="evenodd"></path></svg>
            </span>

            <!-- Camera/Model Info -->
            <div id="camInfoWrap" class="position-absolute top-0 end-0 mt-2 me-2 bg-purple py-1 px-3 rounded-pill">
                <span id="camInfo" class="text-white">
                    Starting Camera...
                </span>
            </div>

            <div id="faceBorder" class="face-border blinking position-absolute top-50 start-50 translate-middle"></div>
            <video id="video">Video stream not available.</video>
        </div>

    </div>

    <!-- Placeholder -->
    <canvas id="canvas" class="d-none"></canvas>
    <div class="output d-none"><img id="photo" alt="The screen capture will appear in this box."></div>
</div>

<!-- Action Buttons -->
<div class="predict-action-btns d-flex flex-column-reverse flex-md-row justify-content-center">
            
    <!-- Upload Photo -->
    <button class="upload-btn btn bg-purple text-white d-flex align-items-center mt-0 mt-md-4" data-bs-toggle="modal" data-bs-target="#exampleModal">
        <span>
            <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M3 17a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM6.293 6.707a1 1 0 010-1.414l3-3a1 1 0 011.414 0l3 3a1 1 0 01-1.414 1.414L11 5.414V13a1 1 0 11-2 0V5.414L7.707 6.707a1 1 0 01-1.414 0z" clip-rule="evenodd"></path></svg>
        </span>
        <span class="ms-2 me-1">Upload Photo</span>
    </button>

    <!-- Toggle AutoCapture -->
    <a href="/set-cookie?autoCapture={{'ON' if autoCapture == 'OFF' else 'OFF'}}&page=predict" class="my-2 mt-md-4 mx-md-4 text-decoration-none">
        <button class="toggle-auto-btn btn bg-{{'grey' if autoCapture == 'OFF' else 'green'}} text-white d-flex align-items-center">
            <span>
                <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M5 2a1 1 0 011 1v1h1a1 1 0 010 2H6v1a1 1 0 01-2 0V6H3a1 1 0 010-2h1V3a1 1 0 011-1zm0 10a1 1 0 011 1v1h1a1 1 0 110 2H6v1a1 1 0 11-2 0v-1H3a1 1 0 110-2h1v-1a1 1 0 011-1zM12 2a1 1 0 01.967.744L14.146 7.2 17.5 9.134a1 1 0 010 1.732l-3.354 1.935-1.18 4.455a1 1 0 01-1.933 0L9.854 12.8 6.5 10.866a1 1 0 010-1.732l3.354-1.935 1.18-4.455A1 1 0 0112 2z" clip-rule="evenodd"></path></svg>
            </span>
            <span class="ms-2 me-1">Auto Capture: <span class="fw-bold">{{autoCapture}}</span></span>
        </button>
    </a>

    <!-- Take Photo -->
    <button id="startbutton" class="take-photo-btn btn bg-purple text-white d-flex align-items-center mt-3 mt-md-4">
        <span>
            <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4 5a2 2 0 00-2 2v8a2 2 0 002 2h12a2 2 0 002-2V7a2 2 0 00-2-2h-1.586a1 1 0 01-.707-.293l-1.121-1.121A2 2 0 0011.172 3H8.828a2 2 0 00-1.414.586L6.293 4.707A1 1 0 015.586 5H4zm6 9a3 3 0 100-6 3 3 0 000 6z" clip-rule="evenodd"></path></svg>
        </span>
        <span class="ms-2 me-1">Take Photo</span>
    </button>
</div>

<!-- Modal -->
<div class="modal fade" id="exampleModal" tabindex="-1" aria-labelledby="exampleModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-dialog-centered">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="exampleModalLabel">Upload Photo</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <form action="/predict" method="post" enctype="multipart/form-data" class="mt-3">
                <div class="modal-body">
                    <div class="mb-3">
                        <input class="form-control" type="file" name="file" id="formFile">
                    </div>
                </div>
                <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Close</button>
                    <button type="submit" class="btn bg-purple text-white">Predict</button>
                </div>
            </form>
        </div>
    </div>
</div>

<!-- Loading -->
<div id="loader" class="loading-wrapper position-fixed top-50 start-50 translate-middle">
    <div class="loading"> 
        <svg width="16px" height="12px">
            <polyline id="back" points="1 6 4 6 6 11 10 1 12 6 15 6"></polyline>
            <polyline id="front" points="1 6 4 6 6 11 10 1 12 6 15 6"></polyline>
        </svg>
    </div>
    <span class="loading-text fw-bold text-dark position-absolute top-50 start-50 translate-middle">Loading...</span>
</div>

<script src="{{ url_for('static', filename='js/face-api.min.js') }}"></script>
<script src="{{ url_for('static', filename='js/mobile-check.js') }}"></script>

<script>
"use strict";

// References:
// * https://github.com/mdn/samples-server/tree/master/s/webrtc-capturestill
// * https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/Taking_still_photos

(function () {
    // The width and height of the captured photo. We will set the
    // width to the value defined here, but the height will be
    // calculated based on the aspect ratio of the input stream.

    var width = 800;    // We will scale the photo width to this
    var height = 0;     // This will be computed based on the input stream

    // |streaming| indicates whether or not we're currently streaming
    // video from the camera. Obviously, we start at false.

    var streaming = false;

    // The various HTML elements we need to configure or control. These
    // will be set by the initiateCamera() function.

    var video = null;
    var canvas = null;
    var photo = null;
    var startbutton = null;

    var loader = document.getElementById('loader');
    var pageBody = document.getElementsByTagName('body')[0];
    loader.style.display = 'none';

    // Face API
    function startStream() {
        if (!window.mobileCheck()) {
            Promise.all([faceapi.loadTinyFaceDetectorModel('../static/models')])
            .then(() => {initiateCamera();})
            .catch(e => {console.log(e);});
        } else {
            initiateCamera();
        }
    }

    function initiateCamera() {
        video = document.getElementById('video');
        canvas = document.getElementById('canvas');
        photo = document.getElementById('photo');
        startbutton = document.getElementById('startbutton');

        navigator.mediaDevices.getUserMedia({ video: true, audio: false })
            .then(function (stream) {
                video.srcObject = stream;
                video.play();
            })
            .catch(function (err) {
                console.log("An error occurred: " + err);
            });

        video.addEventListener('canplay', function (ev) {
            if (!streaming) {

                height = video.videoHeight / (video.videoWidth / width);

                // Firefox currently has a bug where the height can't be read from
                // the video, so we will make assumptions if this happens.

                isNaN(height) ? height = width / (4 / 3) : '';

                video.setAttribute('width', width);
                video.setAttribute('height', height);
                canvas.setAttribute('width', width);
                canvas.setAttribute('height', height);
                streaming = true;
            }
        }, false);

        startbutton.addEventListener('click', function (ev) {
            takepicture();
            ev.preventDefault();
        }, false);

        clearphoto();
    }

    // Fill the photo with an indication that none has been captured.

    function clearphoto() {
        var context = canvas.getContext('2d');
        context.fillStyle = "#AAA";
        context.fillRect(0, 0, canvas.width, canvas.height);

        var data = canvas.toDataURL('image/png');
        photo.setAttribute('src', data);
    }

    // Capture a photo by fetching the current contents of the video
    // and drawing it into a canvas, then converting that to a PNG
    // format data URL. By drawing it on an offscreen canvas and then
    // drawing that to the screen, we can change its size and/or apply
    // other changes before drawing it.

    function takepicture() {
        loader.style.display = 'block';
        pageBody.style.overflowY = 'hidden';
        var context = canvas.getContext('2d');
        if (width && height) {
            canvas.width = width;
            canvas.height = height;
            context.drawImage(video, 0, 0, width, height);

            var data = canvas.toDataURL('image/png');
            photo.setAttribute('src', data);
            video.srcObject.getTracks().forEach(track => track.stop());
            upload_to_server(data);
        } else {
            clearphoto();
        }
    }

    // https://stackoverflow.com/questions
    // /48619138/how-to-upload-canvas-and-image-to-the-server-with-javascript
    function upload_to_server(canvasData) {

        return fetch('{{ url_for("predict") }}', {
            method: 'POST',
            headers: {'Content-Type': 'image/png'},
            body: canvasData
        }).then((response) => {
            return response.text();
        }).then((html) => {
            if (html.includes('error-message')) {
                document.body.innerHTML = html;
                // [Hacky] else face detection does not work
                setTimeout(() => {
                    // window.location.reload();
                    window.location.replace('{{ url_for("predict") }}');
                }, 2000);
            } else {
                document.body.innerHTML = html;
                pageBody.style.overflowY = 'scroll';
                video.srcObject.getTracks().forEach(track => track.stop());
            }
        }).catch(err => console.log(err));
    }

    // Run the initiateCamera process once loading is complete.
    window.addEventListener('load', startStream, false);
    
    
    // ===== Using the Face Detection model ===== //
    
    var video = document.getElementById('video');
    
    video.addEventListener('play', () => {
        
        if (!window.mobileCheck()) {
            
            // [Hacky] else it'll show error in faceapi.createCanvasFromMedia(video)
            new Promise((res, rej) => {
                setTimeout(() => { res() }, 100);
            }).then(() => {
                const canvas = faceapi.createCanvasFromMedia(video);
                document.getElementById('videoWrap').append(canvas);
                
                const displaySize = { width: video.width, height: video.height }
                faceapi.matchDimensions(canvas, displaySize);
                
                var no_detection_count = 0;
                var prev_detection = null;
                var detect_interval_ms = 125;
                var perfect_lapse_ms = 0;
                var picture_taken = false;
                var lapse = false;
                var auto_capture = '{{autoCapture}}';
                
                var face_border = document.getElementById('faceBorder');
                var camInfoWrap = document.getElementById('camInfoWrap');
                var camInfo = document.getElementById('camInfo');
        
                camInfo.innerHTML = 'Loading Model...';
                
                // 'lapse' indicate if countdown should continue
                // 't' indicates the countdown time in seconds
                function automatic_capture(lapse, t=3) {
                    
                    if (!picture_taken && lapse && auto_capture == 'ON') {
                        perfect_lapse_ms += detect_interval_ms;
                        
                        for (let i=1; i<=t; i++) {
                            perfect_lapse_ms <= (-i+t+1)*1000
                                ? camInfo.innerHTML = `Predicting in ${i}`
                                : '';
                        }
                        
                        if (perfect_lapse_ms >= t*1000) {
                            takepicture();
                            picture_taken = true;
                            perfect_lapse_ms = 0;
                        }
                    } else if (!lapse) {
                        perfect_lapse_ms = 0;
                    }
                }
        
                // Detect for every interval
                setInterval(async () => {
                
                    const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
                    
                    let resizedDetections = faceapi.resizeResults(detections, displaySize);
        
                    // Prevent detector from turning on and off
                    if (resizedDetections.length == 0 && prev_detection != null) {
                        no_detection_count += 1;
                        no_detection_count <= 10 ? resizedDetections = prev_detection : '';
                    } else if (resizedDetections.length >= 1) {
                        no_detection_count = 0;
                        prev_detection = resizedDetections;
                    }
        
                    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                    faceapi.draw.drawDetections(canvas, resizedDetections);
                    
                    // Check if the center of the detection box is within a threshold of the center box
                    if (typeof resizedDetections[0] != 'undefined') {
                        const dtc = resizedDetections[0]._box;
                        let dc_x, dc_y;
            
                        dc_x = (dtc._width / 2) + dtc._x;
                        dc_y = (dtc._height / 2) + dtc._y;
                        
                        let distance = ((400 - dc_x) ** 2 + (300 - dc_y) ** 2) ** 0.5;
            
                        if (distance < 100) {
                            face_border.style.borderColor = '#00B358';
                            face_border.classList.remove("blinking");
                            face_border.classList.remove("blinking-fast");
                            camInfoWrap.style.backgroundColor = '#00B358';
                            camInfo.innerHTML = 'Perfect';
                            automatic_capture(lapse=true);
                        } else {
                            face_border.style.borderColor = '#FF9200';
                            face_border.classList.add("blinking");
                            face_border.classList.remove("blinking-fast");
                            camInfoWrap.style.backgroundColor = '#FF9200';
                            camInfo.innerHTML = 'Move to the Box';
                            automatic_capture(lapse=false);
                        }
                        
                    } else {
                        face_border.style.borderColor = '#FF0000';
                        face_border.classList.remove("blinking");
                        face_border.classList.add("blinking-fast");
                        camInfoWrap.style.backgroundColor = '#FF0000';
                        camInfo.innerHTML = 'No face detected';
                        automatic_capture(lapse=false);
                    }
        
                }, detect_interval_ms);
            });
        } else {
            camInfo.innerHTML = 'Mobile | Auto Capture Disabled';
            var face_border = document.getElementById('faceBorder');
            face_border.style.display = "none";
        }
    }, false);
})();

</script>

{% endblock %}